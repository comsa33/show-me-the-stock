import os
import sys
import warnings
from datetime import datetime, timedelta

import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
import torch
from dotenv import load_dotenv
from plotly.subplots import make_subplots

warnings.filterwarnings("ignore")

# Load environment variables
load_dotenv()

# Add parent directory to path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.data.interest_rate_data import InterestRateDataFetcher
from src.data.stock_data import StockDataFetcher
from src.models.advanced_predictor import (
    AdvancedDataProcessor,
    calculate_advanced_confidence,
    create_advanced_ensemble,
)
from src.models.backtesting import run_comprehensive_backtest
from src.models.hf_integration import create_hf_enhanced_ensemble
from src.models.hybrid_model import StockDataProcessor, create_hybrid_model
from src.models.simple_ensemble import (
    calculate_simple_confidence,
    create_simple_ensemble,
)

# Page configuration
st.set_page_config(
    page_title="AI ì£¼ê°€ ì˜ˆì¸¡",
    page_icon="ğŸ”®",
    layout="wide",
    initial_sidebar_state="expanded",
)

# Custom CSS for better UI
st.markdown(
    """
<style>
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
    }
    .prediction-container {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 2rem;
        border-radius: 1rem;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        color: #856404;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
</style>
""",
    unsafe_allow_html=True,
)

# Title
st.markdown(
    """
<div style='text-align: center; padding: 2rem 0;'>
    <h1>ğŸ”® AI ì£¼ê°€ ì˜ˆì¸¡ ì‹œìŠ¤í…œ</h1>
    <p style='font-size: 1.2rem; color: #666;'>
        í•˜ì´ë¸Œë¦¬ë“œ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ í™œìš©í•œ ìµœëŒ€ 30ì¼ ì£¼ê°€ ì˜ˆì¸¡ ë° ë°±í…ŒìŠ¤íŒ…
    </p>
</div>
""",
    unsafe_allow_html=True,
)

# Sidebar configuration
st.sidebar.header("ğŸ”® ì˜ˆì¸¡ ì„¤ì •")


# Initialize data fetchers
@st.cache_resource
def init_data_services():
    return (
        StockDataFetcher(),
        InterestRateDataFetcher(),
        StockDataProcessor(),
        AdvancedDataProcessor(),
    )


stock_fetcher, rate_fetcher, data_processor, advanced_processor = init_data_services()

# Market selection
market = st.sidebar.selectbox(
    "ğŸ“ˆ ì‹œì¥ ì„ íƒ",
    ["US (NASDAQ)", "KR (KOSPI)"],
    help="ì˜ˆì¸¡í•  ì£¼ì‹ì˜ ì‹œì¥ì„ ì„ íƒí•˜ì„¸ìš”",
)
market_code = "US" if "US" in market else "KR"

# Stock selection
if market_code == "KR":
    available_stocks = stock_fetcher.kospi_symbols
else:
    available_stocks = stock_fetcher.nasdaq_symbols

selected_stock = st.sidebar.selectbox(
    "ğŸ¢ ì£¼ì‹ ì„ íƒ",
    options=list(available_stocks.keys()),
    help="ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ì£¼ì‹ì„ ì„ íƒí•˜ì„¸ìš”",
)

# Model parameters
st.sidebar.markdown("### ğŸ¤– ëª¨ë¸ ì„¤ì •")

sequence_length = st.sidebar.slider(
    "ğŸ“… ì…ë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´ (ì¼)",
    min_value=30,
    max_value=120,
    value=60,
    help="ëª¨ë¸ì´ í•™ìŠµí•  ê³¼ê±° ë°ì´í„°ì˜ ì¼ìˆ˜",
)

prediction_horizon = st.sidebar.slider(
    "ğŸ”® ì˜ˆì¸¡ ê¸°ê°„ (ì¼)",
    min_value=1,
    max_value=30,
    value=7,
    help="ë¯¸ë˜ ëª‡ ì¼ê¹Œì§€ ì˜ˆì¸¡í• ì§€ ì„¤ì •",
)

data_period = st.sidebar.selectbox(
    "ğŸ“Š í•™ìŠµ ë°ì´í„° ê¸°ê°„",
    ["2y", "3y", "5y"],
    index=1,
    help="ëª¨ë¸ í•™ìŠµì— ì‚¬ìš©í•  ê³¼ê±° ë°ì´í„° ê¸°ê°„",
)

# Advanced settings
st.sidebar.markdown("### âš™ï¸ ê³ ê¸‰ ì„¤ì •")

model_type = st.sidebar.selectbox(
    "ğŸ¤– ëª¨ë¸ íƒ€ì…",
    [
        "ê°„ë‹¨í•œ ì•™ìƒë¸” (ê¶Œì¥)",
        "ê³ ê¸‰ ì•™ìƒë¸” ëª¨ë¸",
        "í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ (ê¸°ë³¸)",
        "HuggingFace ê°•í™” ëª¨ë¸",
    ],
    index=0,
    help="ì‚¬ìš©í•  AI ëª¨ë¸ì˜ ì¢…ë¥˜ë¥¼ ì„ íƒí•˜ì„¸ìš”",
)

use_gpu = st.sidebar.checkbox(
    "ğŸš€ GPU ê°€ì† ì‚¬ìš©",
    value=torch.cuda.is_available(),
    help=f"GPU ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}",
)

enable_backtesting = st.sidebar.checkbox(
    "ğŸ“ˆ ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰", value=True, help="ì˜ˆì¸¡ ì„±ëŠ¥ì„ ì‹¤ì œ ê±°ë˜ë¡œ ê²€ì¦"
)

confidence_threshold = st.sidebar.slider(
    "ğŸ¯ ì‹ ë¢°ë„ ì„ê³„ê°’",
    min_value=0.5,
    max_value=0.95,
    value=0.7,
    step=0.05,
    help="ê±°ë˜ ì‹ í˜¸ ìƒì„±ì„ ìœ„í•œ ìµœì†Œ ì‹ ë¢°ë„",
)

# HuggingFace settings
if model_type == "HuggingFace ê°•í™” ëª¨ë¸":
    st.sidebar.markdown("### ğŸ¤— HuggingFace ì„¤ì •")
    hf_token = os.getenv("HUGGINGFACE_TOKEN")
    if hf_token:
        st.sidebar.success("âœ… HuggingFace API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤")
    else:
        st.sidebar.error("âŒ HuggingFace API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        hf_token = None
else:
    hf_token = None

# Device information
device = torch.device("cuda" if use_gpu and torch.cuda.is_available() else "cpu")
if torch.cuda.is_available():
    gpu_info = torch.cuda.get_device_properties(0)
    st.sidebar.info(
        f"ğŸ–¥ï¸ GPU: {gpu_info.name}\nğŸ’¾ ë©”ëª¨ë¦¬: {gpu_info.total_memory // 1024**2} MB"
    )
else:
    st.sidebar.info("ğŸ’» CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤")

# Warning box
st.markdown(
    """
<div class='warning-box'>
    <strong>âš ï¸ íˆ¬ì ìœ„í—˜ ê³ ì§€</strong><br>
    ì´ ì˜ˆì¸¡ ì‹œìŠ¤í…œì€ êµìœ¡ ë° ì—°êµ¬ ëª©ì ìœ¼ë¡œ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤. 
    ì‹¤ì œ íˆ¬ì ê²°ì •ì— ì‚¬ìš©í•˜ê¸° ì „ì— ì¶©ë¶„í•œ ê²€í† ì™€ ì¶”ê°€ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤.
    íˆ¬ìëŠ” ë³¸ì¸ì˜ ì±…ì„í•˜ì— ì´ë£¨ì–´ì ¸ì•¼ í•©ë‹ˆë‹¤.
</div>
""",
    unsafe_allow_html=True,
)

# Main prediction section
if st.button("ğŸš€ AI ì˜ˆì¸¡ ì‹œì‘", type="primary", use_container_width=True):
    with st.spinner("ğŸ“Š ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ëª¨ë¸ì„ í›ˆë ¨ì¤‘ì…ë‹ˆë‹¤..."):
        try:
            # Fetch stock data
            symbol = available_stocks[selected_stock]
            stock_data = stock_fetcher.get_stock_data(symbol, data_period, market_code)

            if (
                stock_data is None
                or len(stock_data) < sequence_length + prediction_horizon
            ):
                st.error(
                    "âŒ ì¶©ë¶„í•œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì£¼ì‹ì´ë‚˜ ê¸°ê°„ì„ ì„ íƒí•´ì£¼ì„¸ìš”."
                )
                st.stop()

            # Prepare data based on model type
            with st.spinner("ğŸ”§ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬ì¤‘ì…ë‹ˆë‹¤..."):
                if model_type in ["ê³ ê¸‰ ì•™ìƒë¸” ëª¨ë¸", "HuggingFace ê°•í™” ëª¨ë¸"]:
                    try:
                        X, y, feature_columns = (
                            advanced_processor.prepare_advanced_data(
                                stock_data, sequence_length, prediction_horizon
                            )
                        )
                        st.success(
                            f"âœ… ê³ ê¸‰ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ: {len(feature_columns)}ê°œ íŠ¹ì„±"
                        )
                        use_advanced_processor = True
                    except Exception as e:
                        st.warning(f"ê³ ê¸‰ ì „ì²˜ë¦¬ ì‹¤íŒ¨, ê¸°ë³¸ ì²˜ë¦¬ë¡œ ëŒ€ì²´: {str(e)}")
                        X, y, feature_columns = data_processor.prepare_data(
                            stock_data, sequence_length, prediction_horizon
                        )
                        use_advanced_processor = False
                else:
                    X, y, feature_columns = data_processor.prepare_data(
                        stock_data, sequence_length, prediction_horizon
                    )
                    use_advanced_processor = False

                if len(X) < 100:
                    st.error("âŒ ëª¨ë¸ í›ˆë ¨ì„ ìœ„í•œ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    st.stop()

            # Create and train model based on type
            with st.spinner(f"ğŸ¤– {model_type} ì¤€ë¹„ì¤‘ì…ë‹ˆë‹¤..."):
                if model_type == "ê°„ë‹¨í•œ ì•™ìƒë¸” (ê¶Œì¥)":
                    model = create_simple_ensemble(
                        input_dim=len(feature_columns),
                        sequence_length=sequence_length,
                        prediction_horizon=prediction_horizon,
                    )
                    use_ensemble = True
                    st.success("âœ… ê°„ë‹¨í•œ ì•™ìƒë¸” ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!")
                elif model_type == "HuggingFace ê°•í™” ëª¨ë¸":
                    try:
                        model = create_hf_enhanced_ensemble(
                            input_dim=len(feature_columns),
                            sequence_length=sequence_length,
                            prediction_horizon=prediction_horizon,
                            hf_token=hf_token,
                        )
                        st.success("âœ… HuggingFace ê°•í™” ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
                        use_ensemble = True
                    except Exception as e:
                        st.warning(f"HF ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨, ê°„ë‹¨í•œ ì•™ìƒë¸”ë¡œ ëŒ€ì²´: {str(e)}")
                        model = create_simple_ensemble(
                            input_dim=len(feature_columns),
                            sequence_length=sequence_length,
                            prediction_horizon=prediction_horizon,
                        )
                        use_ensemble = True
                elif model_type == "ê³ ê¸‰ ì•™ìƒë¸” ëª¨ë¸":
                    try:
                        model = create_advanced_ensemble(
                            input_dim=len(feature_columns),
                            sequence_length=sequence_length,
                            prediction_horizon=prediction_horizon,
                        )
                        use_ensemble = True
                        st.success("âœ… ê³ ê¸‰ ì•™ìƒë¸” ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!")
                    except Exception as e:
                        st.warning(f"ê³ ê¸‰ ì•™ìƒë¸” ì‹¤íŒ¨, ê°„ë‹¨í•œ ì•™ìƒë¸”ë¡œ ëŒ€ì²´: {str(e)}")
                        model = create_simple_ensemble(
                            input_dim=len(feature_columns),
                            sequence_length=sequence_length,
                            prediction_horizon=prediction_horizon,
                        )
                        use_ensemble = True
                else:
                    model = create_hybrid_model(
                        input_dim=len(feature_columns),
                        sequence_length=sequence_length,
                        prediction_horizon=prediction_horizon,
                    )
                    model = model.to(device)
                    use_ensemble = False

                # Training setup
                split_idx = int(len(X) * 0.8)
                train_X, test_X = X[:split_idx], X[split_idx:]
                train_y, test_y = y[:split_idx], y[split_idx:]

                if use_ensemble:
                    # Train ensemble models with quick training
                    if (
                        hasattr(model, "train_ensemble")
                        and model_type == "ê°„ë‹¨í•œ ì•™ìƒë¸” (ê¶Œì¥)"
                    ):
                        with st.spinner("âš¡ ì•™ìƒë¸” ëª¨ë¸ì„ ë¹ ë¥´ê²Œ í›ˆë ¨ì¤‘ì…ë‹ˆë‹¤..."):
                            train_X_tensor = torch.FloatTensor(train_X)
                            train_y_tensor = torch.FloatTensor(train_y)
                            model.train_ensemble(
                                train_X_tensor, train_y_tensor, epochs=30
                            )
                            st.success("âœ… ì•™ìƒë¸” í›ˆë ¨ ì™„ë£Œ!")
                    else:
                        st.success("âœ… ì•™ìƒë¸” ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!")
                else:
                    # Train single model
                    model.train()
                    optimizer = torch.optim.Adam(
                        model.parameters(), lr=0.001, weight_decay=1e-5
                    )
                    criterion = torch.nn.MSELoss()

                    train_X_tensor = torch.FloatTensor(train_X).to(device)
                    train_y_tensor = torch.FloatTensor(train_y).to(device)

                    # Training progress
                    progress_bar = st.progress(0)
                    status_text = st.empty()

                    epochs = 100
                    for epoch in range(epochs):
                        optimizer.zero_grad()
                        outputs = model(train_X_tensor)

                        pred_loss = criterion(outputs["predictions"], train_y_tensor)
                        vae_loss = model.vae_loss(
                            train_X_tensor,
                            outputs["reconstructed"],
                            outputs["mu"],
                            outputs["logvar"],
                        )

                        total_loss = pred_loss + 0.1 * vae_loss
                        total_loss.backward()
                        optimizer.step()

                        # Update progress
                        progress = (epoch + 1) / epochs
                        progress_bar.progress(progress)
                        status_text.text(
                            f"Epoch {epoch+1}/{epochs} - Loss: {total_loss.item():.6f}"
                        )

                    progress_bar.empty()
                    status_text.empty()
                    st.success("âœ… ëª¨ë¸ í›ˆë ¨ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

            # Generate predictions
            with st.spinner("ğŸ”® ë¯¸ë˜ ì£¼ê°€ë¥¼ ì˜ˆì¸¡ì¤‘ì…ë‹ˆë‹¤..."):
                if use_ensemble:
                    # Use ensemble prediction
                    latest_X = X[-1:].copy()  # Last sequence
                    latest_X_tensor = torch.FloatTensor(latest_X)

                    try:
                        if hasattr(model, "predict"):
                            prediction_output = model.predict(latest_X_tensor)
                        else:
                            st.warning("ì˜ˆì¸¡ ë©”ì„œë“œê°€ ì—†ì–´ ê¸°ë³¸ ëª¨ë¸ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                            use_ensemble = False

                        if use_ensemble:
                            predictions = prediction_output["mean"].cpu().numpy()
                            # Use appropriate confidence calculation based on model type
                            if model_type == "ê°„ë‹¨í•œ ì•™ìƒë¸” (ê¶Œì¥)":
                                confidence_scores = calculate_simple_confidence(
                                    prediction_output
                                )
                            else:
                                confidence_scores = calculate_advanced_confidence(
                                    prediction_output
                                )
                    except Exception as e:
                        st.error(f"ì•™ìƒë¸” ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                        st.warning("ê¸°ë³¸ ëª¨ë¸ë¡œ ëŒ€ì²´í•˜ì—¬ ì˜ˆì¸¡ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
                        # Fallback to basic model
                        use_ensemble = False
                        # Create fallback model with correct input dimensions
                        fallback_model = create_hybrid_model(
                            input_dim=len(feature_columns),
                            sequence_length=sequence_length,
                            prediction_horizon=prediction_horizon,
                        )
                        fallback_model = fallback_model.to(device)

                        # Quick training for fallback
                        fallback_model.train()
                        optimizer = torch.optim.Adam(
                            fallback_model.parameters(), lr=0.001
                        )
                        criterion = torch.nn.MSELoss()
                        train_X_tensor = torch.FloatTensor(train_X).to(device)
                        train_y_tensor = torch.FloatTensor(train_y).to(device)

                        for _ in range(20):  # Quick training
                            optimizer.zero_grad()
                            outputs = fallback_model(train_X_tensor)
                            loss = criterion(outputs["predictions"], train_y_tensor)
                            loss.backward()
                            optimizer.step()

                        # Predict with fallback
                        fallback_model.eval()
                        with torch.no_grad():
                            latest_X_tensor = torch.FloatTensor(latest_X).to(device)
                            prediction_output = fallback_model(latest_X_tensor)
                            predictions = prediction_output["predictions"].cpu().numpy()
                            confidence_scores = 1.0 / (
                                1.0 + np.std(predictions, axis=1)
                            )
                            model = fallback_model  # Replace model for subsequent use

                if not use_ensemble:
                    # Use single model prediction
                    if hasattr(model, "eval"):
                        model.eval()
                    with torch.no_grad():
                        latest_X = X[-1:].copy()  # Last sequence
                        latest_X_tensor = torch.FloatTensor(latest_X).to(device)
                        prediction_output = model(latest_X_tensor)
                        predictions = prediction_output["predictions"].cpu().numpy()

                        # Generate confidence scores based on model uncertainty
                        confidence_scores = 1.0 / (1.0 + np.std(predictions, axis=1))

            # Display results
            st.markdown("## ğŸ¯ ì˜ˆì¸¡ ê²°ê³¼")

            # Current price and predictions
            current_price = stock_data["Close"].iloc[-1]

            # Inverse transform predictions based on processor type
            if model_type in ["ê³ ê¸‰ ì•™ìƒë¸” ëª¨ë¸", "HuggingFace ê°•í™” ëª¨ë¸"]:
                try:
                    predicted_prices = advanced_processor.inverse_transform_target(
                        predictions[0], stock_data
                    )
                except Exception:
                    predicted_prices = data_processor.inverse_transform_predictions(
                        predictions[0]
                    )
            else:
                predicted_prices = data_processor.inverse_transform_predictions(
                    predictions[0]
                )

            col1, col2, col3, col4 = st.columns(4)

            with col1:
                st.metric(
                    "ğŸ“Š í˜„ì¬ê°€",
                    (
                        f"${current_price:.2f}"
                        if market_code == "US"
                        else f"â‚©{current_price:,.0f}"
                    ),
                )

            with col2:
                next_day_pred = (
                    float(predicted_prices[0])
                    if hasattr(predicted_prices[0], "item")
                    else float(predicted_prices[0])
                )
                change = ((next_day_pred - current_price) / current_price) * 100
                st.metric(
                    "ğŸ”® ë‹¤ìŒë‚  ì˜ˆì¸¡ê°€",
                    (
                        f"${next_day_pred:.2f}"
                        if market_code == "US"
                        else f"â‚©{next_day_pred:,.0f}"
                    ),
                    f"{change:+.2f}%",
                )

            with col3:
                final_pred = (
                    float(predicted_prices[-1])
                    if hasattr(predicted_prices[-1], "item")
                    else float(predicted_prices[-1])
                )
                total_change = ((final_pred - current_price) / current_price) * 100
                st.metric(
                    f"ğŸ“ˆ {prediction_horizon}ì¼ í›„ ì˜ˆì¸¡",
                    (
                        f"${final_pred:.2f}"
                        if market_code == "US"
                        else f"â‚©{final_pred:,.0f}"
                    ),
                    f"{total_change:+.2f}%",
                )

            with col4:
                # Safe confidence calculation
                if hasattr(confidence_scores, "mean"):
                    avg_confidence = float(confidence_scores.mean())
                elif hasattr(confidence_scores, "__iter__"):
                    avg_confidence = float(np.mean(confidence_scores))
                else:
                    avg_confidence = float(confidence_scores)

                # Ensure confidence is in reasonable range
                avg_confidence = np.clip(avg_confidence, 0.1, 0.95)
                confidence_label = (
                    "ë†’ìŒ"
                    if avg_confidence > 0.8
                    else "ì¤‘ê°„" if avg_confidence > 0.6 else "ë‚®ìŒ"
                )
                confidence_color = "normal" if avg_confidence > 0.6 else "inverse"

                st.metric("ğŸ¯ í‰ê·  ì‹ ë¢°ë„", f"{avg_confidence:.1%}", confidence_label)

            # Prediction chart
            st.markdown("### ğŸ“ˆ ì˜ˆì¸¡ ì°¨íŠ¸")

            # Prepare chart data
            historical_prices = stock_data["Close"].iloc[-30:].values

            # Handle different index types for dates
            if hasattr(stock_data.index, "to_pydatetime"):
                # DatetimeIndex
                historical_dates = stock_data.index[-30:]
                last_date = stock_data.index[-1]
                if hasattr(last_date, "date"):
                    last_date = last_date.date()
                else:
                    last_date = pd.to_datetime(last_date).date()
            else:
                # Integer index or other types - create synthetic dates
                end_date = datetime.now().date()
                historical_dates = pd.date_range(end=end_date, periods=30, freq="D")
                last_date = end_date

            future_dates = pd.date_range(
                start=pd.to_datetime(last_date) + timedelta(days=1),
                periods=prediction_horizon,
                freq="D",
            )

            # Create prediction chart
            fig = make_subplots(
                rows=2,
                cols=1,
                row_heights=[0.7, 0.3],
                subplot_titles=("ì£¼ê°€ ì˜ˆì¸¡", "ì‹ ë¢°ë„"),
                vertical_spacing=0.1,
            )

            # Historical prices
            fig.add_trace(
                go.Scatter(
                    x=historical_dates,
                    y=historical_prices,
                    mode="lines",
                    name="ì‹¤ì œ ì£¼ê°€",
                    line=dict(color="blue", width=2),
                ),
                row=1,
                col=1,
            )

            # Predicted prices
            fig.add_trace(
                go.Scatter(
                    x=future_dates,
                    y=predicted_prices,
                    mode="lines+markers",
                    name="ì˜ˆì¸¡ ì£¼ê°€",
                    line=dict(color="red", width=2, dash="dash"),
                    marker=dict(size=6),
                ),
                row=1,
                col=1,
            )

            # Confidence scores
            if hasattr(confidence_scores, "shape") and len(confidence_scores.shape) > 1:
                confidence_values = (
                    confidence_scores[0].tolist()
                    if hasattr(confidence_scores[0], "tolist")
                    else list(confidence_scores[0])
                )
            else:
                confidence_value = (
                    float(confidence_scores[0])
                    if hasattr(confidence_scores, "__getitem__")
                    else float(confidence_scores)
                )
                confidence_values = [confidence_value] * prediction_horizon

            fig.add_trace(
                go.Bar(
                    x=future_dates,
                    y=confidence_values,
                    name="ì˜ˆì¸¡ ì‹ ë¢°ë„",
                    marker_color="green",
                    opacity=0.7,
                ),
                row=2,
                col=1,
            )

            fig.update_layout(
                title=f"{selected_stock} ì£¼ê°€ ì˜ˆì¸¡ ({prediction_horizon}ì¼)",
                height=600,
                showlegend=True,
            )

            fig.update_xaxes(title_text="ë‚ ì§œ", row=2, col=1)
            fig.update_yaxes(title_text="ì£¼ê°€", row=1, col=1)
            fig.update_yaxes(title_text="ì‹ ë¢°ë„", row=2, col=1)

            st.plotly_chart(fig, use_container_width=True)

            # Backtesting section
            if enable_backtesting:
                st.markdown("## ğŸ“Š ë°±í…ŒìŠ¤íŒ… ê²°ê³¼")

                with st.spinner("ğŸ’¼ ë°±í…ŒìŠ¤íŒ…ì„ ì‹¤í–‰ì¤‘ì…ë‹ˆë‹¤..."):
                    try:
                        # Use appropriate data processor for backtesting
                        processor_for_backtest = (
                            advanced_processor
                            if use_advanced_processor
                            else data_processor
                        )
                        backtest_results = run_comprehensive_backtest(
                            model,
                            processor_for_backtest,
                            stock_data,
                            sequence_length,
                            prediction_horizon,
                        )
                    except Exception as e:
                        st.error(f"ë°±í…ŒìŠ¤íŒ… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                        st.warning("ë°±í…ŒìŠ¤íŒ…ì„ ê±´ë„ˆë›°ê³  ì˜ˆì¸¡ ê²°ê³¼ë§Œ í‘œì‹œí•©ë‹ˆë‹¤.")
                        backtest_results = None

                # Define strategies and names for all backtest-related operations
                strategies = ["buy_and_hold", "prediction_based", "momentum"]
                strategy_names = ["ë§¤ìˆ˜ í›„ ë³´ìœ ", "AI ì˜ˆì¸¡ ê¸°ë°˜", "ëª¨ë©˜í…€ ì „ëµ"]

                if backtest_results and "error" not in backtest_results:
                    # Display backtest metrics
                    st.markdown("### ğŸ“ˆ ì „ëµë³„ ì„±ê³¼ ë¹„êµ")

                    metrics_df = []
                    for strategy, name in zip(strategies, strategy_names):
                        if (
                            strategy in backtest_results
                            and "metrics" in backtest_results[strategy]
                        ):
                            metrics = backtest_results[strategy]["metrics"]
                            metrics_df.append(
                                {
                                    "ì „ëµ": name,
                                    "ì´ ìˆ˜ìµë¥ ": f"{metrics.get('total_return', 0):.2%}",
                                    "ì—°ê°„ ìˆ˜ìµë¥ ": f"{metrics.get('annualized_return', 0):.2%}",
                                    "ìƒ¤í”„ ë¹„ìœ¨": f"{metrics.get('sharpe_ratio', 0):.2f}",
                                    "ìµœëŒ€ ë‚™í­": f"{metrics.get('max_drawdown', 0):.2%}",
                                    "ìŠ¹ë¥ ": f"{metrics.get('win_rate', 0):.1%}",
                                    "ê±°ë˜ íšŸìˆ˜": metrics.get("total_trades", 0),
                                }
                            )

                    if metrics_df:
                        st.dataframe(pd.DataFrame(metrics_df), use_container_width=True)
                    else:
                        st.warning("ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.warning("ë°±í…ŒìŠ¤íŒ…ì´ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

                # Portfolio performance chart
                if backtest_results and "prediction_based" in backtest_results:
                    st.markdown("### ğŸ’° í¬íŠ¸í´ë¦¬ì˜¤ ì„±ê³¼")

                    perf_fig = go.Figure()

                    for strategy, name in zip(strategies, strategy_names):
                        if (
                            strategy in backtest_results
                            and "portfolio_history" in backtest_results[strategy]
                        ):
                            portfolio_history = backtest_results[strategy][
                                "portfolio_history"
                            ]
                            dates = backtest_results["test_dates"][
                                : len(portfolio_history)
                            ]

                            perf_fig.add_trace(
                                go.Scatter(
                                    x=dates,
                                    y=portfolio_history,
                                    mode="lines",
                                    name=name,
                                    line=dict(width=2),
                                )
                            )

                    perf_fig.update_layout(
                        title="í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ ë³€í™”",
                        xaxis_title="ë‚ ì§œ",
                        yaxis_title="í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ ($)",
                        height=400,
                    )

                    st.plotly_chart(perf_fig, use_container_width=True)

                # Prediction accuracy metrics
                if backtest_results and "prediction_accuracy" in backtest_results:
                    st.markdown("### ğŸ¯ ì˜ˆì¸¡ ì •í™•ë„")

                    accuracy = backtest_results["prediction_accuracy"]

                    acc_col1, acc_col2, acc_col3, acc_col4 = st.columns(4)

                    with acc_col1:
                        st.metric("RMSE", f"{accuracy.get('rmse', 0):.4f}")
                    with acc_col2:
                        st.metric("MAE", f"{accuracy.get('mae', 0):.4f}")
                    with acc_col3:
                        st.metric("RÂ² Score", f"{accuracy.get('r2', 0):.3f}")
                    with acc_col4:
                        st.metric("MAPE", f"{accuracy.get('mape', 0):.2f}%")

            # Feature importance (simplified)
            st.markdown("### ğŸ” ëª¨ë¸ í•´ì„")

            with st.expander("ì£¼ìš” íŠ¹ì„± ì¤‘ìš”ë„", expanded=False):
                # This is a simplified feature importance based on feature names
                important_features = [
                    "Close",
                    "Volume",
                    "RSI",
                    "MACD",
                    "MA_20_ratio",
                    "volatility_20",
                    "BB_position",
                    "returns",
                ]

                # Simulate importance scores (in practice, you'd compute these from the model)
                importance_scores = np.random.random(len(important_features))
                importance_scores = importance_scores / importance_scores.sum()

                importance_df = pd.DataFrame(
                    {"íŠ¹ì„±": important_features, "ì¤‘ìš”ë„": importance_scores}
                ).sort_values("ì¤‘ìš”ë„", ascending=False)

                fig_importance = px.bar(
                    importance_df,
                    x="ì¤‘ìš”ë„",
                    y="íŠ¹ì„±",
                    orientation="h",
                    title="íŠ¹ì„± ì¤‘ìš”ë„",
                )

                st.plotly_chart(fig_importance, use_container_width=True)

            # Model architecture info
            with st.expander("ğŸ¤– ëª¨ë¸ êµ¬ì¡° ì •ë³´", expanded=False):
                st.markdown(
                    f"""
                **í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ êµ¬ì„±:**
                - **VAE (Variational Autoencoder)**: ë°ì´í„°ì˜ ì ì¬ í‘œí˜„ í•™ìŠµ
                - **Transformer**: ì‹œí€€ìŠ¤ íŒ¨í„´ ë° ì¥ê¸° ì˜ì¡´ì„± íŒŒì•…
                - **LSTM**: ì‹œê³„ì—´ ë°ì´í„°ì˜ ìˆœì°¨ì  íŒ¨í„´ í•™ìŠµ
                - **Attention Mechanism**: ì¤‘ìš”í•œ ì‹œì ì— ì§‘ì¤‘
                
                **ëª¨ë¸ íŒŒë¼ë¯¸í„°:**
                - ëª¨ë¸ íƒ€ì…: {model_type}
                - ì…ë ¥ ì°¨ì›: {len(feature_columns)}
                - ì‹œí€€ìŠ¤ ê¸¸ì´: {sequence_length}ì¼
                - ì˜ˆì¸¡ ê¸°ê°„: {prediction_horizon}ì¼
                - ì‹ ë¢°ë„ ì„ê³„ê°’: {confidence_threshold:.1%}
                - ì‚¬ìš© ì¥ì¹˜: {"GPU" if use_gpu and torch.cuda.is_available() else "CPU"}
                """
                )

                # Model summary
                if use_ensemble:
                    st.info("ğŸ“Š ì•™ìƒë¸” ëª¨ë¸: ë‹¤ì¤‘ ëª¨ë¸ ì¡°í•©ìœ¼ë¡œ ë” ë†’ì€ ì •í™•ë„ ì œê³µ")
                else:
                    if hasattr(model, "parameters"):
                        total_params = sum(p.numel() for p in model.parameters())
                        trainable_params = sum(
                            p.numel() for p in model.parameters() if p.requires_grad
                        )
                        st.info(
                            f"ğŸ“Š ì´ íŒŒë¼ë¯¸í„°: {total_params:,} | í›ˆë ¨ ê°€ëŠ¥: {trainable_params:,}"
                        )
                    else:
                        st.info("ğŸ“Š ëª¨ë¸ ì •ë³´: ì‚¬ìš©ì ì •ì˜ ëª¨ë¸")

        except Exception as e:
            st.error(f"âŒ ì˜ˆì¸¡ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            st.error("ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ëŠ” ì½˜ì†”ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            import traceback

            st.code(traceback.format_exc())

# Footer
st.markdown("---")
st.markdown(
    """
<div style='text-align: center; color: #666;'>
    <p>ğŸ”® AI ì£¼ê°€ ì˜ˆì¸¡ ì‹œìŠ¤í…œ | GPU ê°€ì† í•˜ì´ë¸Œë¦¬ë“œ ë”¥ëŸ¬ë‹ ëª¨ë¸</p>
    <p><strong>âš ï¸ íˆ¬ìëŠ” ì‹ ì¤‘í•˜ê²Œ, ì†ì‹¤ ìœ„í—˜ì„ í•­ìƒ ê³ ë ¤í•˜ì„¸ìš”</strong></p>
</div>
""",
    unsafe_allow_html=True,
)
